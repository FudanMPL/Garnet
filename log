############# 2024-06-07 16:35:50 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v9, v5) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v10
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v9, v6) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v11
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v10,) {}
output:  v12
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v11, v7) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v13
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v13, v8) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v14
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v14,) {}
output:  v15
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v9, v5) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v10
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v9, v6) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v11
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v10,) {}
output:  v12
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v11, v7) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v13
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v13, v8) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:50 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v14
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v14,) {}
output:  v15
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.362417 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   297369600 online communication bits
  1356595200 offline communication bits
         340 online round
         512 offline round
############# 2024-06-07 16:35:51 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv120_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split121_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv120_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v23, v20) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v24
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v24,)
spilts:  (v25, v26)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v26,) {}
output:  v27
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v25, v21) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v28
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v28, v22) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v29
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v29,) {}
output:  v30
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v23, v20) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v24
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v24,)
spilts:  (v25, v26)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v26,) {}
output:  v27
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v25, v21) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v28
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v28, v22) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v29
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v29,) {}
output:  v30
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:51 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.249645 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   297369600 online communication bits
  1356595200 offline communication bits
         339 online round
         416 offline round
############# 2024-06-07 16:35:52 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv148_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split149_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv148_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v38, v35) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v39
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v39,)
spilts:  (v40, v41)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v41,) {}
output:  v42
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v40, v36) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v43
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v43, v37) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v44
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v44,) {}
output:  v45
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v38, v35) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v39
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v39,)
spilts:  (v40, v41)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v41,) {}
output:  v42
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v40, v36) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v43
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v43, v37) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v44
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v44,) {}
output:  v45
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.210306 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   297369600 online communication bits
  1356595200 offline communication bits
         339 online round
         416 offline round
############# 2024-06-07 16:35:52 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv116_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split117_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv116_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v53, v50) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v54
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v54,)
spilts:  (v55, v56)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v55,) {}
output:  v57
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v56, v51) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v58
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v58, v52) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v59
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v59,) {}
output:  v60
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v53, v50) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v54
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v54,)
spilts:  (v55, v56)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v55,) {}
output:  v57
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v56, v51) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v58
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v58, v52) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:52 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v59
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v59,) {}
output:  v60
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.238201 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   297369600 online communication bits
  1356595200 offline communication bits
         339 online round
         416 offline round
############# 2024-06-07 16:35:53 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv145_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split146_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv145_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v68, v65) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v69
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v69,)
spilts:  (v70, v71)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v70,) {}
output:  v72
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v71, v66) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v73
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v73, v67) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v74
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v74,) {}
output:  v75
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v68, v65) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v69
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v69,)
spilts:  (v70, v71)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v70,) {}
output:  v72
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v71, v66) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v73
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v73, v67) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v74
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v74,) {}
output:  v75
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:53 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.234386 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   297369600 online communication bits
  1356595200 offline communication bits
         339 online round
         416 offline round
############# 2024-06-07 16:35:53 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v85, v81) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v86
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v85, v82) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v87
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v87, v83) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v88
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v88, v84) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v89
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v86,) {}
output:  v91
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v91,)
spilts:  (v92, v93)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v85, v81) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v86
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v85, v82) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v87
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v87, v83) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v88
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v88, v84) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v89
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v86,) {}
output:  v91
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v91,)
spilts:  (v92, v93)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.383636 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:35:54 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v103, v99) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v104
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v103, v100) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v105
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v105, v101) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v106
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v106, v102) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v107
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v107,) {}
output:  v109
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v109,)
spilts:  (v110, v111)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v103, v99) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v104
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v103, v100) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v105
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v105, v101) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v106
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v106, v102) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v107
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v107,) {}
output:  v109
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v109,)
spilts:  (v110, v111)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:54 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.338575 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:35:54 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v121, v117) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v122
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v121, v118) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v123
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v123, v119) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v124
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v124, v120) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v125
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v125,) {}
output:  v127
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v127,)
spilts:  (v128, v129)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v121, v117) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v122
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v121, v118) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v123
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v123, v119) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v124
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v124, v120) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v125
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v125,) {}
output:  v127
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v127,)
spilts:  (v128, v129)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.941298 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:35:55 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v139, v135) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v140
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v139, v136) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v141
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v141, v137) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v142
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v142, v138) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v143
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v140,) {}
output:  v145
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v145,)
spilts:  (v146, v147)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v139, v135) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:55 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v140
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v139, v136) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v141
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v141, v137) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v142
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v142, v138) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v143
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v140,) {}
output:  v145
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v145,)
spilts:  (v146, v147)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.933430 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:35:56 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv112_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv112_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v157, v153) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v158
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v157, v154) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v159
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v159, v155) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v160
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v160, v156) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v161
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v161,) {}
output:  v162
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v157, v153) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v158
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v157, v154) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v159
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v159, v155) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v160
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v160, v156) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v161
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v161,) {}
output:  v162
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:56 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.147840 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:35:57 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv113_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv113_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v172, v168) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v173
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v172, v169) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v174
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v173,) {}
output:  v175
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v174, v170) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v176
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v176, v171) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v177
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v172, v168) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v173
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v172, v169) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v174
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v173,) {}
output:  v175
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v174, v170) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v176
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v176, v171) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v177
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.083706 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:35:57 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv162_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split163_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv162_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v185, v182) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v186
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v186,)
spilts:  (v187, v188)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v187, v183) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v189
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v189, v184) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v190
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v188,) {}
output:  v192
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v192,)
spilts:  (v193, v194)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v185, v182) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v186
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v186,)
spilts:  (v187, v188)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v187, v183) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v189
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v189, v184) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:57 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v190
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v188,) {}
output:  v192
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v192,)
spilts:  (v193, v194)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.192902 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:35:58 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv175_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split176_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv175_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v202, v199) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v203
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v203,)
spilts:  (v204, v205)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v204, v200) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v206
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v206, v201) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v207
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v205,) {}
output:  v209
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v209,)
spilts:  (v210, v211)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v202, v199) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v203
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v203,)
Compiled 100000 lines at Fri Jun  7 16:35:58 2024
spilts:  (v204, v205)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v204, v200) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v206
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v206, v201) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v207
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v205,) {}
output:  v209
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v209,)
spilts:  (v210, v211)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:58 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.259897 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:35:59 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv172_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split173_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv172_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v219, v216) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v220
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v220,)
spilts:  (v221, v222)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v222, v217) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v223
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v223, v218) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v224
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v221,) {}
output:  v226
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v226,)
spilts:  (v227, v228)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v219, v216) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v220
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v220,)
spilts:  (v221, v222)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v222, v217) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v223
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v223, v218) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v224
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v221,) {}
output:  v226
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v226,)
spilts:  (v227, v228)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.230333 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:35:59 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv158_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split159_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv158_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v236, v233) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v237
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v237,)
spilts:  (v238, v239)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v239, v234) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v240
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v240, v235) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v241
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v238,) {}
output:  v243
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v243,)
spilts:  (v244, v245)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v236, v233) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v237
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v237,)
spilts:  (v238, v239)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v239, v234) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:35:59 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v240
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v240, v235) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v241
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v238,) {}
output:  v243
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v243,)
spilts:  (v244, v245)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.252745 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:00 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv169_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv169_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v255, v251) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v256
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v255, v252) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v257
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v256,) {}
output:  v258
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v257, v253) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v259
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v259, v254) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v260
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v258,)
spilts:  (v262, v263)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v255, v251) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v256
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v255, v252) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v257
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v256,) {}
output:  v258
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v257, v253) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v259
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v259, v254) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v260
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v258,)
spilts:  (v262, v263)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.343344 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         332 online round
         448 offline round
############# 2024-06-07 16:36:00 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv162_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split163_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv187_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv162_weight
_initializer_Conv108_weight
_initializer_Conv187_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v271, v268) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v272
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v272,)
spilts:  (v273, v274)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v273, v269) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v275
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v274,) {}
output:  v276
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v275, v270) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v277
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v276,)
spilts:  (v279, v280)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v271, v268) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:00 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v272
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v272,)
spilts:  (v273, v274)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v273, v269) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v275
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v274,) {}
output:  v276
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v275, v270) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v277
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v276,)
spilts:  (v279, v280)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.240824 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:01 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv172_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split173_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv195_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv172_weight
_initializer_Conv108_weight
_initializer_Conv195_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v288, v285) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v289
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v289,)
spilts:  (v290, v291)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v291, v286) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v292
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v290,) {}
output:  v293
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v292, v287) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v294
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v293,)
spilts:  (v296, v297)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v288, v285) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v289
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v289,)
spilts:  (v290, v291)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v291, v286) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v292
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v290,) {}
output:  v293
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v292, v287) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v294
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v293,)
spilts:  (v296, v297)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:01 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.290892 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:02 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv158_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split159_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv202_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv158_weight
_initializer_Conv108_weight
_initializer_Conv202_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v305, v302) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v306
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v306,)
spilts:  (v307, v308)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v308, v303) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v309
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v307,) {}
output:  v310
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v309, v304) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v311
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v310,)
spilts:  (v313, v314)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v305, v302) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v306
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v306,)
spilts:  (v307, v308)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v308, v303) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v309
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v307,) {}
output:  v310
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v309, v304) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v311
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v310,)
spilts:  (v313, v314)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:02 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.216743 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:02 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv175_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split176_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv219_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv175_weight
_initializer_Conv108_weight
_initializer_Conv219_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v322, v319) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v323
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v323,)
spilts:  (v324, v325)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v324, v320) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v326
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v325,) {}
output:  v327
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v326, v321) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v328
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v327,)
spilts:  (v330, v331)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v322, v319) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v323
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v323,)
spilts:  (v324, v325)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v324, v320) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v326
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v325,) {}
output:  v327
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v326, v321) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v328
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v327,)
spilts:  (v330, v331)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.247023 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:03 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv231_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split232_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv231_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v339, v336) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v340
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v340,)
spilts:  (v341, v342)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v341, v337) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v343
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v343, v338) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v344
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v344,) {}
output:  v346
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v346,)
spilts:  (v347, v348)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v339, v336) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v340
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v340,)
spilts:  (v341, v342)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v341, v337) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v343
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v343, v338) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:03 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v344
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v344,) {}
output:  v346
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v346,)
spilts:  (v347, v348)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.809690 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:04 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv247_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split248_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv247_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v356, v353) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v357
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v357,)
spilts:  (v358, v359)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v358, v354) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v360
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v360, v355) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v361
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v361,) {}
output:  v363
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v363,)
spilts:  (v364, v365)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v356, v353) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v357
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v357,)
spilts:  (v358, v359)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v358, v354) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v360
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v360, v355) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:04 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v361
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v361,) {}
output:  v363
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v363,)
spilts:  (v364, v365)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:05 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.807306 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:05 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv227_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split228_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv227_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v373, v370) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v374
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v374,)
spilts:  (v375, v376)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v376, v371) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v377
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v377, v372) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v378
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v378,) {}
output:  v380
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v380,)
spilts:  (v381, v382)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v373, v370) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:05 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:05 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v374
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v374,)
spilts:  (v375, v376)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v376, v371) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v377
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v377, v372) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v378
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v378,) {}
output:  v380
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v380,)
Compiled 200000 lines at Fri Jun  7 16:36:06 2024
spilts:  (v381, v382)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.847122 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:06 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv244_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split245_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv244_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v390, v387) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v391
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v391,)
spilts:  (v392, v393)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v393, v388) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v394
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v394, v389) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v395
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v395,) {}
output:  v397
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v397,)
spilts:  (v398, v399)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v390, v387) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:06 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v391
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v391,)
spilts:  (v392, v393)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v393, v388) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:07 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:07 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v394
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v394, v389) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:07 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:07 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v395
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v395,) {}
output:  v397
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v397,)
spilts:  (v398, v399)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
Processing basic block Fri Jun  7 16:36:07 2024
WARNING: Order of memory instructions not preserved, errors possible
Profiling time: 3.835917 (ms)
Writing to /home/lx/Garnet/Programs/Schedules/testonnx.sch
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-0.bc
Program requires at most:
   154828800 online communication bits
  1120665600 offline communication bits
         331 online round
         352 offline round
############# 2024-06-07 16:36:07 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat250_fwd0', 'Conv251_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Relu
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv251_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v407, v404) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v408
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v408, v405) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v409
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v409, v406) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v411
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v411,) {}
output:  v412
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v412,)
spilts:  (v413, v414)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v407, v404) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:07 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v408
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v408, v405) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v409
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v409, v406) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:08 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:08 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat240_fwd0', 'Conv242_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Relu
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv242_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v422, v419) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v423
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v423, v420) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v424
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v424, v421) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v426
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v426,) {}
output:  v427
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v427,)
spilts:  (v428, v429)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v422, v419) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v423
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v423, v420) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v424
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v424, v421) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:08 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:08 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv238_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Concat
node:  Split
node:  Add
_initializer_Conv238_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v439, v435) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v440
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v439, v436) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v441
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v441, v437) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v442
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v442, v438) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v443
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v443,) {}
output:  v444
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v444,)
spilts:  (v446, v447)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v439, v435) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v440
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v439, v436) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v441
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v441, v437) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v442
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v442, v438) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v443
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v443,) {}
output:  v444
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v444,)
spilts:  (v446, v447)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:08 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (10242, 's')

############# 2024-06-07 16:36:08 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv279_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split280_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv113_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv279_weight
_initializer_Conv108_weight
_initializer_Conv113_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v455, v452) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v456
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v456,)
spilts:  (v457, v458)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v458,) {}
output:  v459
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v457, v453) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v460
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v460, v454) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v461
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v455, v452) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:08 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v456
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v456,)
spilts:  (v457, v458)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v458,) {}
output:  v459
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v457, v453) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v460
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v460, v454) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v461
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:09 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:09 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv296_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split297_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv113_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv296_weight
_initializer_Conv108_weight
_initializer_Conv113_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v469, v466) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v470
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v470,)
spilts:  (v471, v472)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v472,) {}
output:  v473
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v471, v467) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v474
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v474, v468) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v475
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v469, v466) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v470
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v470,)
spilts:  (v471, v472)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v472,) {}
output:  v473
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v471, v467) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v474
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v474, v468) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v475
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:09 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:09 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv275_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split276_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv113_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv275_weight
_initializer_Conv108_weight
_initializer_Conv113_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v483, v480) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v484
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v484,)
spilts:  (v485, v486)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v485,) {}
output:  v487
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v486, v481) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v488
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v488, v482) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v489
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v483, v480) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v484
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v484,)
spilts:  (v485, v486)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v485,) {}
output:  v487
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v486, v481) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v488
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v488, v482) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v489
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:09 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:09 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv293_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Relu
node:  Conv
node input:  ['Split294_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv113_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv293_weight
_initializer_Conv108_weight
_initializer_Conv113_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v497, v494) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v498
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v498,)
spilts:  (v499, v500)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v499,) {}
output:  v501
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v500, v495) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v502
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v502, v496) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v503
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v497, v494) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v498
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v498,)
spilts:  (v499, v500)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v499,) {}
output:  v501
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v500, v495) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v502
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v502, v496) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:09 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v503
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:10 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:10 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv272_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv113_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv272_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv113_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v513, v509) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v514
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v513, v510) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v515
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v515, v511) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v516
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v516, v512) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v517
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v513, v509) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v514
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v513, v510) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v515
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v515, v511) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v516
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v516, v512) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v517
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:10 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:10 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv286_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv285_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Add
_initializer_Conv286_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv285_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v527, v523) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v528
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v527, v524) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v529
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v529, v525) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v530
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v530, v526) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v531
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v531,) {}
output:  v532
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v527, v523) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v528
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v527, v524) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v529
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v529, v525) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v530
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v530, v526) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v531
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v531,) {}
output:  v532
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:10 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:10 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat319_fwd0', 'Conv321_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Relu
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv321_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v540, v537) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v541
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v541, v538) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v542
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v540, v539) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v544
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v544,) {}
output:  v545
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v545,)
spilts:  (v546, v547)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v540, v537) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v541
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v541, v538) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v542
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v540, v539) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:10 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:10 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat329_fwd0', 'Conv330_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Relu
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv330_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v555, v552) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v556
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v556, v553) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v557
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v555, v554) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v559
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v559,) {}
output:  v560
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v560,)
spilts:  (v561, v562)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v555, v552) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v556
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v556, v553) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:10 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v557
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v555, v554) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:10 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:11 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv105_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv317_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv105_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv317_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v572, v568) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v573
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v572, v569) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v574
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v573,) {}
output:  v575
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v574, v570) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v576
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v576, v571) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v577
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v575,)
spilts:  (v579, v580)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v572, v568) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v573
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v572, v569) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v574
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v573,) {}
output:  v575
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v574, v570) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v576
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v576, v571) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v577
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v575,)
spilts:  (v579, v580)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:11 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:11 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv340_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split341_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv169_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv340_weight
_initializer_Conv108_weight
_initializer_Conv169_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v588, v585) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v589
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v589,)
Compiled 300000 lines at Fri Jun  7 16:36:11 2024
spilts:  (v590, v591)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v590, v586) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v592
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v591,) {}
output:  v593
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v592, v587) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v594
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v593,)
spilts:  (v596, v597)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v588, v585) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v589
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v589,)
spilts:  (v590, v591)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v590, v586) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v592
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v591,) {}
output:  v593
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v592, v587) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v594
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v593,)
spilts:  (v596, v597)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:11 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:11 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv357_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split358_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv169_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv357_weight
_initializer_Conv108_weight
_initializer_Conv169_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v605, v602) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v606
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v606,)
spilts:  (v607, v608)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v607, v603) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v609
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v608,) {}
output:  v610
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v609, v604) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v611
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v610,)
spilts:  (v613, v614)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v605, v602) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:11 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v606
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v606,)
spilts:  (v607, v608)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v607, v603) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v609
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v608,) {}
output:  v610
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v609, v604) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v611
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v610,)
spilts:  (v613, v614)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:12 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:12 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv336_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split337_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv169_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv336_weight
_initializer_Conv108_weight
_initializer_Conv169_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v622, v619) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v623
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v623,)
spilts:  (v624, v625)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v625, v620) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v626
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v624,) {}
output:  v627
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v626, v621) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v628
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v627,)
spilts:  (v630, v631)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v622, v619) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v623
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v623,)
spilts:  (v624, v625)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v625, v620) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v626
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v624,) {}
output:  v627
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v626, v621) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v628
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v627,)
spilts:  (v630, v631)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:12 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:12 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv354_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split355_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv169_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv354_weight
_initializer_Conv108_weight
_initializer_Conv169_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v639, v636) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v640
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v640,)
spilts:  (v641, v642)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v642, v637) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v643
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v641,) {}
output:  v644
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v643, v638) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v645
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v644,)
spilts:  (v647, v648)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v639, v636) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v640
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v640,)
spilts:  (v641, v642)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v642, v637) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v643
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v641,) {}
output:  v644
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v643, v638) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v645
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v644,)
spilts:  (v647, v648)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:12 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:12 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv333_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv169_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv333_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv169_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v658, v654) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v659
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v658, v655) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v660
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v660, v656) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v661
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v661, v657) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v662
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v659,)
spilts:  (v664, v665)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v658, v654) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v659
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v658, v655) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v660
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v660, v656) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v661
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v661, v657) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:12 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v662
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v659,)
spilts:  (v664, v665)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:12 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:12 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv347_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv346_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Concat
node:  Split
node:  Add
_initializer_Conv347_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv346_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v675, v671) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v676
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v675, v672) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v677
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v677, v673) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v678
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v678, v674) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v679
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v679,) {}
output:  v680
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v676,)
spilts:  (v682, v683)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v675, v671) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v676
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v675, v672) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v677
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v677, v673) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v678
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v678, v674) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v679
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v679,) {}
output:  v680
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v676,)
spilts:  (v682, v683)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:13 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:13 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv378_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Concat
node:  Split
node:  Add
_initializer_Conv378_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v693, v689) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v694
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v693, v690) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v695
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v695, v691) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v696
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v696, v692) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v697
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v697,) {}
output:  v698
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v698,)
spilts:  (v700, v701)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v693, v689) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v694
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v693, v690) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v695
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v695, v691) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v696
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v696, v692) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v697
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v697,) {}
output:  v698
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v698,)
spilts:  (v700, v701)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:13 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:13 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv112_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv386_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv112_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv386_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v711, v707) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v712
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v711, v708) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v713
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v713, v709) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v714
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v714, v710) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v715
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v711, v707) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v712
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v711, v708) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v713
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v713, v709) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v714
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v714, v710) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:13 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v715
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:14 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:14 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv391_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv392_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv391_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv392_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v725, v721) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v726
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v725, v722) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v727
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v726,) {}
output:  v728
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v727, v723) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v729
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v729, v724) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v730
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v725, v721) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v726
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v725, v722) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v727
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v726,) {}
output:  v728
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v727, v723) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v729
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v729, v724) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v730
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:14 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:14 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat250_fwd0', 'Conv398_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv398_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v738, v735) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v739
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v739, v736) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v740
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v740, v737) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v742
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v742,)
spilts:  (v743, v744)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v738, v735) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v739
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v739, v736) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v740
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v740, v737) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:14 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:14 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat250_fwd0', 'Conv402_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv402_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v752, v749) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v753
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v753, v750) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v754
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v754, v751) {}
64 256 (1, 32, 10, 10) (256, 64, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 64, 1, 1)
output:  v756
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v756,) {}
output:  v757
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v757,)
spilts:  (v758, v759)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v752, v749) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v753
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v753, v750) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v754
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v754, v751) {}
256 64 (1, 32, 10, 10) (256, 64, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:14 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1143, in decorator
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:14 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv378_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv413_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv378_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv413_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v769, v765) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v770
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v769, v766) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v771
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v771, v767) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v772
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v772, v768) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v773
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v773,)
spilts:  (v775, v776)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v769, v765) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v770
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v769, v766) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v771
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v771, v767) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v772
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v772, v768) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v773
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v773,)
spilts:  (v775, v776)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:14 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:14 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv418_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv419_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv418_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv419_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v786, v782) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v787
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v786, v783) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v788
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v787,) {}
output:  v789
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v788, v784) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v790
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v790, v785) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v791
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v791,)
spilts:  (v793, v794)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v786, v782) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v787
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v786, v783) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v788
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v787,) {}
output:  v789
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v788, v784) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:14 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v790
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v790, v785) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v791
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v791,)
spilts:  (v793, v794)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:15 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:15 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv428_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split429_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv392_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv428_weight
_initializer_Conv108_weight
_initializer_Conv392_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v802, v799) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v803
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v803,)
spilts:  (v804, v805)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v804, v800) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v806
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v805,) {}
output:  v807
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v806, v801) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v808
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v802, v799) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v803
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v803,)
spilts:  (v804, v805)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v804, v800) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v806
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v805,) {}
output:  v807
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v806, v801) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v808
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:15 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:15 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv446_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split447_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv392_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv446_weight
_initializer_Conv108_weight
_initializer_Conv392_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v816, v813) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v817
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v817,)
spilts:  (v818, v819)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v818, v814) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v820
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v819,) {}
output:  v821
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v820, v815) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v822
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v816, v813) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v817
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v817,)
spilts:  (v818, v819)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v818, v814) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v820
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v819,) {}
output:  v821
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v820, v815) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:15 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v822
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:16 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:16 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv432_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split433_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv392_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv432_weight
_initializer_Conv108_weight
_initializer_Conv392_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v830, v827) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v831
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v831,)
spilts:  (v832, v833)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v833, v828) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v834
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v832,) {}
output:  v835
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v834, v829) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v836
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v830, v827) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v831
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v831,)
Compiled 400000 lines at Fri Jun  7 16:36:16 2024
spilts:  (v832, v833)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v833, v828) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v834
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v832,) {}
output:  v835
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v834, v829) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v836
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:16 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:16 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv449_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split450_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv392_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Add
_initializer_Conv449_weight
_initializer_Conv108_weight
_initializer_Conv392_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v844, v841) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v845
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v845,)
spilts:  (v846, v847)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v847, v842) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v848
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v846,) {}
output:  v849
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v848, v843) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v850
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v844, v841) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v845
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v845,)
spilts:  (v846, v847)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v847, v842) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v848
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v846,) {}
output:  v849
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v848, v843) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v850
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:16 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:16 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat250_fwd0', 'Conv457_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv457_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v858, v855) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v859
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v859, v856) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v860
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v860, v857) {}
64 256 (1, 32, 10, 10) (256, 64, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 64, 1, 1)
output:  v862
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v862,)
spilts:  (v863, v864)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v858, v855) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v859
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v859, v856) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v860
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v860, v857) {}
256 64 (1, 32, 10, 10) (256, 64, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:16 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1143, in decorator
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:16 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv475_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split476_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv419_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv475_weight
_initializer_Conv108_weight
_initializer_Conv419_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v872, v869) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v873
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v873,)
spilts:  (v874, v875)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v874, v870) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v876
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v875,) {}
output:  v877
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v876, v871) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v878
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v878,)
spilts:  (v880, v881)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v872, v869) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v873
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v873,)
spilts:  (v874, v875)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v874, v870) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v876
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v875,) {}
output:  v877
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v876, v871) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:16 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v878
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v878,)
spilts:  (v880, v881)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:16 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:16 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv493_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split494_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv419_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv493_weight
_initializer_Conv108_weight
_initializer_Conv419_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v889, v886) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v890
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v890,)
spilts:  (v891, v892)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v891, v887) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v893
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v892,) {}
output:  v894
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v893, v888) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v895
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v895,)
spilts:  (v897, v898)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v889, v886) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v890
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v890,)
spilts:  (v891, v892)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v891, v887) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v893
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v892,) {}
output:  v894
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v893, v888) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v895
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v895,)
spilts:  (v897, v898)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:17 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:17 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv479_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split480_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv419_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv479_weight
_initializer_Conv108_weight
_initializer_Conv419_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v906, v903) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v907
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v907,)
spilts:  (v908, v909)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v909, v904) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v910
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v908,) {}
output:  v911
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v910, v905) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v912
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v912,)
spilts:  (v914, v915)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v906, v903) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v907
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v907,)
spilts:  (v908, v909)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v909, v904) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:17 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v910
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v908,) {}
output:  v911
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v910, v905) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v912
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v912,)
spilts:  (v914, v915)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:18 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:18 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv496_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split497_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv419_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv496_weight
_initializer_Conv108_weight
_initializer_Conv419_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v923, v920) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v924
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v924,)
spilts:  (v925, v926)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v926, v921) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v927
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v925,) {}
output:  v928
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v927, v922) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v929
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v929,)
spilts:  (v931, v932)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v923, v920) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v924
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v924,)
spilts:  (v925, v926)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v926, v921) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v927
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v925,) {}
output:  v928
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v927, v922) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v929
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v929,)
spilts:  (v931, v932)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:18 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:18 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv486_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv485_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Concat
node:  Split
node:  Add
_initializer_Conv486_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv485_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v942, v938) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v943
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v942, v939) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v944
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v944, v940) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v945
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v945, v941) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v946
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v946,) {}
output:  v947
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v947,)
spilts:  (v949, v950)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v942, v938) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v943
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v942, v939) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v944
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v944, v940) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v945
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v945, v941) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v946
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v946,) {}
output:  v947
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v947,)
spilts:  (v949, v950)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:18 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:18 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv347_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv547_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv347_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv547_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v960, v956) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v961
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v960, v957) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v962
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v962, v958) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v963
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v963, v959) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v964
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v961,)
spilts:  (v966, v967)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v960, v956) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v961
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v960, v957) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v962
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v962, v958) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v963
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v963, v959) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v964
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v961,)
spilts:  (v966, v967)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:18 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:18 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat240_fwd0', 'Conv562_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv562_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v975, v972) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v976
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v976, v973) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v977
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v977, v974) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v979
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v979,)
spilts:  (v980, v981)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v975, v972) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v976
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v976, v973) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:18 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v977
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v977, v974) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:18 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:19 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat319_fwd0', 'Conv586_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv586_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v989, v986) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v990
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v990, v987) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v991
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v989, v988) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v993
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v993,)
spilts:  (v994, v995)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v989, v986) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v990
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v990, v987) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v991
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v989, v988) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:19 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:19 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat319_fwd0', 'Conv590_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv590_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1003, v1000) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1004
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1004, v1001) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1005
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1003, v1002) {}
64 256 (1, 32, 10, 10) (256, 64, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 64, 1, 1)
output:  v1007
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1007,) {}
output:  v1008
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1008,)
spilts:  (v1009, v1010)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1003, v1000) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1004
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1004, v1001) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1005
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1003, v1002) {}
256 64 (1, 32, 10, 10) (256, 64, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:19 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1143, in decorator
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:19 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat319_fwd0', 'Conv602_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv602_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1018, v1015) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1019
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1019, v1016) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1020
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1018, v1017) {}
64 256 (1, 32, 10, 10) (256, 64, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 64, 1, 1)
output:  v1022
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1022,)
spilts:  (v1023, v1024)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1018, v1015) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1019
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1019, v1016) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1020
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1018, v1017) {}
256 64 (1, 32, 10, 10) (256, 64, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:19 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1143, in decorator
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:19 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Concat
node:  Conv
node input:  ['Concat329_fwd0', 'Conv635_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)
node:  Split
node:  Add
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv635_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1032, v1029) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1033
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1033, v1030) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1034
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v1032, v1031) {}
64 256 (1, 32, 10, 10) (256, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (256, 32, 1, 1)
output:  v1036
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1036,)
spilts:  (v1037, v1038)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1032, v1029) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1033
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1033, v1030) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1034
NOSTAND
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)>
args:  (v1032, v1031) {}
256 32 (1, 32, 10, 10) (256, 32, 1, 1)
conv-forward
(1, 256, 10, 10)
############# 2024-06-07 16:36:19 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 996, in test_onnx
    model(input)
  File "/home/lx/Garnet/Compiler/nn.py", line 815, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/Convert/model.py", line 261, in forward
    activations[out_op_id] = op(*in_activations)
  File "/home/lx/Garnet/Compiler/nn.py", line 823, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/lx/Garnet/Compiler/nn.py", line 1416, in forward
    return self._conv_forward(input, weight, self.bias)
  File "/home/lx/Garnet/Compiler/nn.py", line 1408, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
  File "/home/lx/Garnet/Compiler/library.py", line 2047, in wrapper
    res = func(*args, **kw)
  File "/home/lx/Garnet/Compiler/functional.py", line 646, in conv2d
    def _(i, j):
  File "/home/lx/Garnet/Compiler/library.py", line 1255, in <lambda>
    return lambda loop_body: new_dec(decorator(loop_body))
  File "/home/lx/Garnet/Compiler/library.py", line 1308, in decorator
    tape = prog.new_tape(f, (0,), 'multithread')  # creating the new tape to be run
  File "/home/lx/Garnet/Compiler/program.py", line 297, in new_tape
    function(*args)
  File "/home/lx/Garnet/Compiler/library.py", line 1298, in f
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 1070, in decorator
    def f(i):
  File "/home/lx/Garnet/Compiler/library.py", line 966, in decorator
    range_loop(loop_body, start, stop, step)
  File "/home/lx/Garnet/Compiler/library.py", line 928, in range_loop
    while_loop(loop_fn, condition, start, g=loop_body.__globals__)
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in while_loop
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1633, in if_statement
    if_fn()
  File "/home/lx/Garnet/Compiler/library.py", line 1486, in <lambda>
    if_statement(pre_condition, lambda: do_while(loop_fn, g=g))
  File "/home/lx/Garnet/Compiler/library.py", line 1560, in do_while
    condition = _run_and_link(loop_fn, g)
  File "/home/lx/Garnet/Compiler/library.py", line 1527, in _run_and_link
    res = function()
  File "/home/lx/Garnet/Compiler/library.py", line 1480, in loop_fn
    result = loop_body(arg)
  File "/home/lx/Garnet/Compiler/library.py", line 916, in loop_fn
    res = loop_body(i)
  File "/home/lx/Garnet/Compiler/library.py", line 1076, in f
    state = reducer(tuplify(loop_body(j)), state)
  File "/home/lx/Garnet/Compiler/library.py", line 1302, in f
    return loop_body(base + i)
  File "/home/lx/Garnet/Compiler/library.py", line 1252, in new_body
    return loop_body(*indices)
  File "/home/lx/Garnet/Compiler/functional.py", line 650, in _
    conv2ds(res, inputs, weights, output_h, output_w,
  File "/home/lx/Garnet/Compiler/instructions.py", line 2969, in __init__
    assert args[2].size == args[7] * args[8] * args[11]
AssertionError

############# 2024-06-07 16:36:19 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv238_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv642_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv238_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv642_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1048, v1044) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1049
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1048, v1045) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1050
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1050, v1046) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1051
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1051, v1047) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1052
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1052,)
spilts:  (v1054, v1055)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1048, v1044) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1049
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1048, v1045) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1050
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1050, v1046) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1051
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1051, v1047) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:19 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v1052
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1052,)
spilts:  (v1054, v1055)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:19 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:19 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv647_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv648_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv647_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv648_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1065, v1061) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1066
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1065, v1062) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1067
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1066,) {}
output:  v1068
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1067, v1063) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1069
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1069, v1064) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1070
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1070,)
spilts:  (v1072, v1073)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1065, v1061) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1066
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1065, v1062) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1067
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1066,) {}
output:  v1068
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1067, v1063) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1069
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1069, v1064) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:20 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v1070
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1070,)
Compiled 500000 lines at Fri Jun  7 16:36:20 2024
spilts:  (v1072, v1073)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:21 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:21 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv675_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split676_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv317_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv675_weight
_initializer_Conv108_weight
_initializer_Conv317_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1081, v1078) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1082
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1082,)
spilts:  (v1083, v1084)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1083, v1079) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1085
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1084,) {}
output:  v1086
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1085, v1080) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1087
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1086,)
spilts:  (v1089, v1090)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1081, v1078) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1082
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1082,)
spilts:  (v1083, v1084)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1083, v1079) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1085
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1084,) {}
output:  v1086
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1085, v1080) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1087
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1086,)
spilts:  (v1089, v1090)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:21 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:21 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv692_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split693_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv317_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv692_weight
_initializer_Conv108_weight
_initializer_Conv317_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1098, v1095) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1099
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1099,)
spilts:  (v1100, v1101)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1100, v1096) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1102
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1101,) {}
output:  v1103
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1102, v1097) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1104
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1103,)
spilts:  (v1106, v1107)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1098, v1095) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1099
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1099,)
spilts:  (v1100, v1101)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1100, v1096) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1102
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1101,) {}
output:  v1103
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1102, v1097) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1104
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1103,)
spilts:  (v1106, v1107)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:21 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:21 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv671_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split672_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv317_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv671_weight
_initializer_Conv108_weight
_initializer_Conv317_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1115, v1112) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1116
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1116,)
spilts:  (v1117, v1118)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1118, v1113) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1119
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1117,) {}
output:  v1120
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1119, v1114) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1121
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1120,)
spilts:  (v1123, v1124)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1115, v1112) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1116
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1116,)
spilts:  (v1117, v1118)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1118, v1113) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:21 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1119
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1117,) {}
output:  v1120
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1119, v1114) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1121
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1120,)
spilts:  (v1123, v1124)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:22 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:22 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv689_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split690_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv317_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv689_weight
_initializer_Conv108_weight
_initializer_Conv317_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1132, v1129) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1133
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1133,)
spilts:  (v1134, v1135)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1135, v1130) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1136
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1134,) {}
output:  v1137
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1136, v1131) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1138
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1137,)
spilts:  (v1140, v1141)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1132, v1129) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1133
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1133,)
spilts:  (v1134, v1135)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1135, v1130) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1136
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1134,) {}
output:  v1137
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1136, v1131) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1138
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1137,)
spilts:  (v1140, v1141)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:22 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:22 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv668_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv317_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv668_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv317_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1151, v1147) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1152
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1151, v1148) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1153
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1153, v1149) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1154
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1154, v1150) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1155
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1152,)
spilts:  (v1157, v1158)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1151, v1147) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1152
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1151, v1148) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1153
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1153, v1149) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1154
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1154, v1150) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:22 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v1155
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1152,)
spilts:  (v1157, v1158)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:23 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:23 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv682_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv681_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Concat
node:  Split
node:  Add
_initializer_Conv682_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv681_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1168, v1164) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1169
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1168, v1165) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1170
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1170, v1166) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1171
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1171, v1167) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1172
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1172,) {}
output:  v1173
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1169,)
spilts:  (v1175, v1176)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1168, v1164) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1169
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1168, v1165) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1170
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1170, v1166) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1171
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1171, v1167) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:23 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v1172
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1172,) {}
output:  v1173
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1169,)
spilts:  (v1175, v1176)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:24 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:24 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv703_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split704_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv648_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv703_weight
_initializer_Conv108_weight
_initializer_Conv648_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1184, v1181) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1185
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1185,)
spilts:  (v1186, v1187)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1186, v1182) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1188
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1187,) {}
output:  v1189
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1188, v1183) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1190
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1190,)
spilts:  (v1192, v1193)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1184, v1181) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1185
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1185,)
spilts:  (v1186, v1187)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1186, v1182) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1188
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1187,) {}
output:  v1189
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1188, v1183) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1190
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1190,)
spilts:  (v1192, v1193)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:24 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:24 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv721_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split722_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv648_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv721_weight
_initializer_Conv108_weight
_initializer_Conv648_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1201, v1198) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1202
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1202,)
spilts:  (v1203, v1204)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1203, v1199) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1205
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1204,) {}
output:  v1206
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1205, v1200) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1207
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1207,)
spilts:  (v1209, v1210)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1201, v1198) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1202
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1202,)
Compiled 600000 lines at Fri Jun  7 16:36:24 2024
spilts:  (v1203, v1204)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1203, v1199) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1205
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1204,) {}
output:  v1206
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1205, v1200) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1207
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1207,)
spilts:  (v1209, v1210)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:24 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:24 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv707_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split708_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv648_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv707_weight
_initializer_Conv108_weight
_initializer_Conv648_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1218, v1215) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1219
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1219,)
spilts:  (v1220, v1221)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1221, v1216) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1222
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1220,) {}
output:  v1223
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1222, v1217) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1224
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1224,)
spilts:  (v1226, v1227)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1218, v1215) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:24 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1219
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1219,)
spilts:  (v1220, v1221)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1221, v1216) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1222
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1220,) {}
output:  v1223
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1222, v1217) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1224
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1224,)
spilts:  (v1226, v1227)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:25 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:25 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv724_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split725_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv648_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv724_weight
_initializer_Conv108_weight
_initializer_Conv648_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1235, v1232) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1236
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1236,)
spilts:  (v1237, v1238)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1238, v1233) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1239
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1237,) {}
output:  v1240
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1239, v1234) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1241
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1241,)
spilts:  (v1243, v1244)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1235, v1232) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1236
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1236,)
spilts:  (v1237, v1238)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1238, v1233) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1239
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1237,) {}
output:  v1240
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1239, v1234) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1241
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1241,)
spilts:  (v1243, v1244)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:25 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:25 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv714_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv713_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Relu
node:  Concat
node:  Split
node:  Add
_initializer_Conv714_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv713_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1254, v1250) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1255
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1254, v1251) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1256
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1256, v1252) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1257
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1257, v1253) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1258
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1258,) {}
output:  v1259
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1259,)
spilts:  (v1261, v1262)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1254, v1250) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1255
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1254, v1251) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1256
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1256, v1252) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1257
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1257, v1253) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:25 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v1258
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1258,) {}
output:  v1259
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1259,)
spilts:  (v1261, v1262)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:26 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:26 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv682_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['data', 'Conv107_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Conv
node input:  ['Conv107_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv738_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv682_weight
_initializer_Conv107_weight
_initializer_Conv108_weight
_initializer_Conv738_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1272, v1268) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1273
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1272, v1269) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 1, 1)
output:  v1274
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1274, v1270) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1275
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1275, v1271) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1276
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1273,)
spilts:  (v1278, v1279)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1272, v1268) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1273
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1272, v1269) {}
32 32 (1, 32, 10, 10) (32, 32, 1, 1)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1274
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1274, v1270) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1275
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1275, v1271) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-7.bc
Processing basic block Fri Jun  7 16:36:26 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-8.bc
output:  v1276
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1273,)
spilts:  (v1278, v1279)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:27 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:27 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv148_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split149_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv148_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1287, v1284) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1288
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1288,)
spilts:  (v1289, v1290)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1289, v1285) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1291
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1291, v1286) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1292
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1290,) {}
output:  v1294
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1294,)
spilts:  (v1295, v1296)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1287, v1284) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1288
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1288,)
spilts:  (v1289, v1290)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1289, v1285) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1291
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1291, v1286) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1292
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1290,) {}
output:  v1294
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1294,)
spilts:  (v1295, v1296)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:27 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:27 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv148_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split149_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv148_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1304, v1301) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1305
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1305,)
spilts:  (v1306, v1307)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1306, v1302) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1308
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1308, v1303) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1309
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1309,) {}
output:  v1311
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1311,)
spilts:  (v1312, v1313)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1304, v1301) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1305
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1305,)
spilts:  (v1306, v1307)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1306, v1302) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1308
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1308, v1303) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:27 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1309
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1309,) {}
output:  v1311
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1311,)
spilts:  (v1312, v1313)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:28 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:28 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv148_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split149_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv148_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1321, v1318) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1322
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1322,)
spilts:  (v1323, v1324)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1323, v1319) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1325
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1325, v1320) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1326
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1326,) {}
output:  v1328
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1328,)
spilts:  (v1329, v1330)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1321, v1318) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1322
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1322,)
spilts:  (v1323, v1324)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1323, v1319) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1325
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1325, v1320) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1326
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1326,) {}
output:  v1328
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1328,)
spilts:  (v1329, v1330)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:28 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:28 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv148_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split149_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv148_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1338, v1335) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1339
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1339,)
spilts:  (v1340, v1341)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1340, v1336) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1342
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1342, v1337) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1343
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1341,) {}
output:  v1345
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1345,)
spilts:  (v1346, v1347)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1338, v1335) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1339
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1339,)
spilts:  (v1340, v1341)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1340, v1336) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1342
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1342, v1337) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1343
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1341,) {}
output:  v1345
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1345,)
Compiled 700000 lines at Fri Jun  7 16:36:28 2024
spilts:  (v1346, v1347)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:28 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:28 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv148_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split149_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv838_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv148_weight
_initializer_Conv108_weight
_initializer_Conv838_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1355, v1352) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1356
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1356,)
spilts:  (v1357, v1358)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1357, v1353) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1359
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1358,) {}
output:  v1360
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1359, v1354) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1361
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1360,)
spilts:  (v1363, v1364)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1355, v1352) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1356
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1356,)
spilts:  (v1357, v1358)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1357, v1353) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:28 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1359
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1358,) {}
output:  v1360
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1359, v1354) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1361
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1360,)
spilts:  (v1363, v1364)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:29 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:29 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv116_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split117_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv116_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1372, v1369) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1373
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1373,)
spilts:  (v1374, v1375)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1375, v1370) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1376
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1376, v1371) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1377
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1374,) {}
output:  v1379
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1379,)
spilts:  (v1380, v1381)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1372, v1369) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1373
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1373,)
spilts:  (v1374, v1375)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1375, v1370) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1376
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1376, v1371) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1377
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1374,) {}
output:  v1379
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1379,)
spilts:  (v1380, v1381)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:29 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:29 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv116_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split117_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv116_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1389, v1386) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1390
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1390,)
spilts:  (v1391, v1392)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1392, v1387) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1393
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1393, v1388) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1394
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1394,) {}
output:  v1396
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1396,)
spilts:  (v1397, v1398)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1389, v1386) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1390
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1390,)
spilts:  (v1391, v1392)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1392, v1387) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1393
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1393, v1388) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1394
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1394,) {}
output:  v1396
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1396,)
spilts:  (v1397, v1398)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:29 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:29 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv116_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split117_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv116_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1406, v1403) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1407
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1407,)
spilts:  (v1408, v1409)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1409, v1404) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1410
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1410, v1405) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1411
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1411,) {}
output:  v1413
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1413,)
spilts:  (v1414, v1415)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1406, v1403) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1407
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1407,)
spilts:  (v1408, v1409)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1409, v1404) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1410
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1410, v1405) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:29 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1411
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1411,) {}
output:  v1413
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1413,)
spilts:  (v1414, v1415)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:30 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:30 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv116_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split117_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv116_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1423, v1420) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1424
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1424,)
spilts:  (v1425, v1426)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1426, v1421) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1427
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1427, v1422) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1428
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1425,) {}
output:  v1430
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1430,)
spilts:  (v1431, v1432)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1423, v1420) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:30 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:30 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1424
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1424,)
spilts:  (v1425, v1426)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1426, v1421) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:30 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:30 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1427
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1427, v1422) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:30 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:30 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1428
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1425,) {}
output:  v1430
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1430,)
spilts:  (v1431, v1432)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:31 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:31 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv116_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split117_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv886_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv116_weight
_initializer_Conv108_weight
_initializer_Conv886_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1440, v1437) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1441
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1441,)
spilts:  (v1442, v1443)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1443, v1438) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1444
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1442,) {}
output:  v1445
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1444, v1439) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1446
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1445,)
spilts:  (v1448, v1449)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1440, v1437) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:31 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:31 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1441
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1441,)
spilts:  (v1442, v1443)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1443, v1438) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1444
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1442,) {}
output:  v1445
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1444, v1439) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1446
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1445,)
spilts:  (v1448, v1449)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:32 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:32 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv145_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split146_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv145_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1457, v1454) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1458
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1458,)
spilts:  (v1459, v1460)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1460, v1455) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1461
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1461, v1456) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1462
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1459,) {}
output:  v1464
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1464,)
spilts:  (v1465, v1466)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1457, v1454) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1458
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1458,)
spilts:  (v1459, v1460)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1460, v1455) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1461
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1461, v1456) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1462
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1459,) {}
output:  v1464
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1464,)
spilts:  (v1465, v1466)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:32 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:32 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv145_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split146_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv145_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1474, v1471) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1475
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1475,)
spilts:  (v1476, v1477)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1477, v1472) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1478
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1478, v1473) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1479
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1479,) {}
output:  v1481
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1481,)
spilts:  (v1482, v1483)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1474, v1471) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1475
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1475,)
spilts:  (v1476, v1477)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1477, v1472) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1478
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1478, v1473) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1479
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1479,) {}
output:  v1481
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1481,)
spilts:  (v1482, v1483)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:32 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:32 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv145_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split146_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv145_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1491, v1488) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1492
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1492,)
spilts:  (v1493, v1494)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1494, v1489) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1495
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1495, v1490) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1496
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1496,) {}
output:  v1498
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1498,)
spilts:  (v1499, v1500)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1491, v1488) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1492
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1492,)
Compiled 800000 lines at Fri Jun  7 16:36:32 2024
spilts:  (v1493, v1494)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1494, v1489) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1495
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1495, v1490) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:32 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1496
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1496,) {}
output:  v1498
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1498,)
spilts:  (v1499, v1500)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:33 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:33 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv145_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split146_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv145_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1508, v1505) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1509
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1509,)
spilts:  (v1510, v1511)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1511, v1506) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1512
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1512, v1507) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1513
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1510,) {}
output:  v1515
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1515,)
spilts:  (v1516, v1517)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1508, v1505) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1509
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1509,)
spilts:  (v1510, v1511)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1511, v1506) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1512
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1512, v1507) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1513
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1510,) {}
output:  v1515
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1515,)
spilts:  (v1516, v1517)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:33 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:33 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv145_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split146_fwd1', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv937_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv145_weight
_initializer_Conv108_weight
_initializer_Conv937_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1525, v1522) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1526
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1526,)
spilts:  (v1527, v1528)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1528, v1523) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1529
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1527,) {}
output:  v1530
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1529, v1524) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1531
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1530,)
spilts:  (v1533, v1534)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1525, v1522) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1526
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1526,)
spilts:  (v1527, v1528)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 32, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1528, v1523) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1529
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1527,) {}
output:  v1530
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1529, v1524) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1531
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1530,)
spilts:  (v1533, v1534)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:33 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:33 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv120_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split121_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv120_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1542, v1539) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1543
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1543,)
spilts:  (v1544, v1545)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1544, v1540) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1546
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1546, v1541) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1547
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1545,) {}
output:  v1549
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1549,)
spilts:  (v1550, v1551)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1542, v1539) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:33 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1543
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1543,)
spilts:  (v1544, v1545)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1544, v1540) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1546
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1546, v1541) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1547
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1545,) {}
output:  v1549
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1549,)
spilts:  (v1550, v1551)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:34 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:34 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv120_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split121_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv120_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1559, v1556) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1560
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1560,)
spilts:  (v1561, v1562)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1561, v1557) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1563
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1563, v1558) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1564
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1564,) {}
output:  v1566
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1566,)
spilts:  (v1567, v1568)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1559, v1556) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1560
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1560,)
spilts:  (v1561, v1562)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1561, v1557) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1563
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1563, v1558) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1564
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1564,) {}
output:  v1566
NOSTAND
MULTIOUTPUT op:  Split(dim=0)
spilt input:  (v1566,)
spilts:  (v1567, v1568)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:34 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:34 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv120_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split121_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv120_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1576, v1573) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1577
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1577,)
spilts:  (v1578, v1579)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1578, v1574) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1580
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1580, v1575) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1581
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1581,) {}
output:  v1583
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1583,)
spilts:  (v1584, v1585)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1576, v1573) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1577
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1577,)
spilts:  (v1578, v1579)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1578, v1574) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1580
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1580, v1575) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1581
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1581,) {}
output:  v1583
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1583,)
spilts:  (v1584, v1585)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:34 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:34 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv120_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split121_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Conv
node input:  ['Conv108_fwd0', 'Conv109_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Relu
node:  Split
node:  Add
_initializer_Conv120_weight
_initializer_Conv108_weight
_initializer_Conv109_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1593, v1590) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1594
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1594,)
spilts:  (v1595, v1596)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1595, v1591) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1597
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1597, v1592) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1598
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1596,) {}
output:  v1600
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1600,)
spilts:  (v1601, v1602)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1593, v1590) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:34 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1594
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1594,)
spilts:  (v1595, v1596)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1595, v1591) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1597
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1597, v1592) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1598
NOSTAND
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1596,) {}
output:  v1600
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1600,)
spilts:  (v1601, v1602)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:35 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

############# 2024-06-07 16:36:35 ############
Default bit length: 63
Default security parameter: 40
Compiling: testonnx from compile_func
node:  Conv
node input:  ['data', 'Conv120_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Split
node:  Conv
node input:  ['Split121_fwd0', 'Conv108_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
node:  Relu
node:  Conv
node input:  ['Conv108_fwd0', 'Conv991_weight']
layer:  <class 'Compiler.nn.Conv2d'>
final layer:  Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
node:  Concat
node:  Split
node:  Add
_initializer_Conv120_weight
_initializer_Conv108_weight
_initializer_Conv991_weight
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1610, v1607) {}
32 160 (1, 32, 10, 10) (160, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (160, 32, 1, 1)
output:  v1611
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1611,)
spilts:  (v1612, v1613)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1612, v1608) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (32, 32, 3, 3)
output:  v1614
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1613,) {}
output:  v1615
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1614, v1609) {}
32 128 (1, 32, 10, 10) (128, 32, 1, 1)
conv_in_size:  (1, 32, 10, 10)
conv_w_size:  (128, 32, 1, 1)
output:  v1616
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1615,)
spilts:  (v1618, v1619)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1610, v1607) {}
160 32 (1, 32, 10, 10) (160, 32, 1, 1)
conv-forward
(1, 160, 10, 10)
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-1.bc
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-2.bc
output:  v1611
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1611,)
spilts:  (v1612, v1613)
MULTIOUTPUT size:  (1, 32, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>
args:  (v1612, v1608) {}
32 32 (1, 32, 10, 10) (32, 32, 3, 3)
conv-forward
(1, 32, 10, 10)
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-3.bc
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-4.bc
output:  v1614
NOSTAND
forward:  <bound method ReLU.forward of ReLU(inplace=True)>
args:  (v1613,) {}
output:  v1615
NOSTAND
forward:  <bound method Conv2d.forward of Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)>
args:  (v1614, v1609) {}
128 32 (1, 32, 10, 10) (128, 32, 1, 1)
conv-forward
(1, 128, 10, 10)
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-5.bc
Processing basic block Fri Jun  7 16:36:35 2024
WARNING: Order of memory instructions not preserved, errors possible
Writing to /home/lx/Garnet/Programs/Bytecode/testonnx-multithread-6.bc
output:  v1616
NOSTAND
NOSTAND
MULTIOUTPUT op:  Split(dim=1)
spilt input:  (v1615,)
spilts:  (v1618, v1619)
MULTIOUTPUT size:  (1, 128, 10, 10)
MULTIOUTPUT size:  (1, 128, 10, 10)
NOSTAND
(1, 128, 10, 10) (1, 128, 10, 10)
[1, 2, 3] [1, 2, 3]
############# 2024-06-07 16:36:37 ############
Traceback (most recent call last):
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1030, in MPCprofiling
    index,round,comm,offround,offcomm = profiling(subGraphs[i], in_size, i)
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 1003, in profiling
    compiler.compile_func()
  File "/home/lx/Garnet/Compiler/compilerLib.py", line 419, in compile_func
    self.compile_function()
  File "/home/lx/anaconda3/envs/Garnet/lib/python3.8/site-packages/taso-0.1.0-py3.8-linux-x86_64.egg/taso/__init__.py", line 999, in test_onnx
    reset_gloabal_store()
  File "/home/lx/Garnet/Compiler/tensor.py", line 3533, in reset_gloabal_store
    item.value.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 7543, in delete
    self.array.delete()
  File "/home/lx/Garnet/Compiler/types.py", line 5616, in delete
    self.value_type.free(self.address)
  File "/home/lx/Garnet/Compiler/types.py", line 4211, in free
    return cls.int_type.free(addr)
  File "/home/lx/Garnet/Compiler/types.py", line 762, in free
    program.free(addr, cls.reg_type)
  File "/home/lx/Garnet/Compiler/program.py", line 485, in free
    size = self.allocated_mem_blocks.pop((addr, mem_type))
KeyError: (None, 's')

