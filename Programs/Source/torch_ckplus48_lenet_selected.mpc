program.options_from_args()
program.use_trunc_pr = True
program.use_split(3)

from Compiler import sorting
import torch
import torch.nn as nn
import os
from Compiler import ml

tf = ml
ml.set_n_threads(5)

def PairwiseDistance(f,flen,num):
    ans=sfix(0.0)
    a=f[0]
    b=f[num]
    for i in range(flen):
        ans+=(a[i]-b[i])*(a[i]-b[i])
    return ans

def func(f1,f2):
    dis=0.0
    for i in range(len(f1)):
        dis+=(f1[i]-f2[i])*(f1[i]-f2[i])
    return dis

def ReadFeature(path):
    f=open(path,'r')
    data=f.readline().split()
    feature=[]
    for i in range(len(data)):
        feature.append(float(data[i]))
    f.close()
    return feature

os.system('pwd')
filelist=['ck_plus_48_feature.txt','cifar100_feature.txt','ferplus_feature.txt']
modellist=['./Compiler/DL/checkpoint/ckpt_cifar100_lenet.pth','./Compiler/DL/checkpoint/ckpt_ferplus_lenet.pth']
namelist=['0.weight', '0.bias', '3.weight', '3.bias', '8.weight', '8.bias', '10.weight', '10.bias']
featurepath='./Compiler/DL/AvgFeature-All/'
f1=ReadFeature(featurepath+filelist[0])
modelnum=len(filelist)-1
for i in range(modelnum):
    f2=ReadFeature(featurepath+filelist[i+1])
    print(func(f1,f2))
featurelen=512
features = MultiArray([len(filelist),featurelen], sfix)
features.input_from(1)

k=Array(modelnum,sfix)
v=Array(modelnum,sint)

for i in range(modelnum):
    k[i]=PairwiseDistance(features,featurelen,i+1)
    print_ln("%s",k[i].reveal())
    v[i]=i

sorting.radix_sort(k,v)

training_samples = MultiArray([882, 32, 32, 3], sfix)
training_labels = MultiArray([882, 7], sint)
test_samples = MultiArray([99, 32, 32, 3], sfix)
test_labels = MultiArray([99, 7], sint)
#
training_labels.input_from(0)
training_samples.input_from(0)
test_labels.input_from(0)
test_samples.input_from(0)

# res = sfix.Tensor([1,12])
# res.input_from(2)

net=[]

for i in range(len(modellist)):
    tmpnet=torch.load(modellist[i],map_location='cpu')
    mynet = nn.Sequential(
        nn.Conv2d(3, 20, 5),
        nn.ReLU(),
        nn.MaxPool2d(2),
        nn.Conv2d(20, 50, 5),
        nn.ReLU(),
        nn.MaxPool2d(2),
        nn.Flatten(),
        nn.ReLU(),
        nn.Linear(1250, 500),
        nn.ReLU(),
        nn.Linear(500, 7)
    )
    mydict = mynet.state_dict()
    tmpdict=tmpnet.state_dict()
    for j in range(len(namelist)):
        name = namelist[j]
        if ('10.' not in name):
            mydict[name] = tmpdict[name]
    mynet.load_state_dict(mydict)
    flag=sfix.from_sint((v[0]-i)!=0)
    net=ml.layers_from_torch_select(mynet,net,str(i),flag,training_samples.shape, 256, input_via=2)

print_ln("%s",net[0].bias.reveal())
optimizer = ml.SGD(net)
optimizer.fit(
    training_samples,
    training_labels,
    epochs=9,
    batch_size=256,
    validation_data=(test_samples, test_labels),
    program=program,
    reset=False,
    print_accuracy=True
)
