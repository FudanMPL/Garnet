## XGboost推理

**九月份更新:** 基于三方安全点积操作，我们设计了新的XGBoost推理协议，将通信量从与树节点数量成正比降低到与树节点数量的二次根号成正比。对于深层的XGBoost模型，此优化可将秘密分享下的安全推理通信量减少数十倍，显著提高了其在带宽受限场景的应用性。

目前支持两种XGboost推理，一种是基于秘密分享下的安全推理，另外一种是两方下的同态加密安全推理。

使用这两种安全推理的前三个步骤是一致的：

（1）首先根据需要修改Programs/Source/xgboost-inference.mpc文件。需要修改的配置如下：

```
m = 4 # 特征数
h = 2 # 树高
tree_number = 2 # 树的数量
n_threads = 4 # 最大线程数
test_samples = 51 # 测试样本数
attribute_max_values = [ # 各个特征的最大值，用于在两方同态加密下使用
100,
100,
100,
100
]

```

（2）编译该mpc文件

```
python3 ./compile.py -R 64 xgboost-inference
```

（3）准备数据

我们假设，模型被第0方持有，数据被第1方持有。

（1）我们首先在Player-Data/Input-P0-0中写入xgboost模型数据。例如，一个由3颗树高为2的决策树模型所组成的xgboost的数据如下。其中，每一行代表一个节点。如果当前行有三个整数值，则代表这一行的节点是内部节点。三个值分别代表节点的编码，节点分裂使用的是第几个属性以及节点分裂的属性阈值。如果当前行有1个整数值和一个浮点数，则代表这一行是叶子节点，整数值代表叶子节点的编号，浮点值则代表叶子节点的预测值。每一层的编号从0-2^h-1。其中，编号为k且在第i层，则它的左子节点为第i+1层编号为k的节点，右子节点为第i+1层编号为k+2^i的节点。
    注意：请确保输入的xgboost模型数据需要保证为满二叉树的结构，即第0层有1个节点，第一层有2个节点，以此类推。考虑到，某些节点可能只有左子节点或者右子节点，因此，不存在的节点的数据可以由-1进行占位。


```
0 2 26
0 2 10
1 2 49
0 0.909088
1 0.467285
2 0.997375
3 0.0177917
0 2 26
0 1 42
1 3 16
0 0.50116
1 0.247406
2 0.455734
3 -0.0153046
0 2 48
0 2 26
1 0 57
0 0.251801
1 -0.205444
2 0.134003
3 0.00747681

```

（2）我们在Player-Data/Input-P1-0中写入需要推理的数据。首先写入所有数据的真实标签，如果没有的话，可以使用任意数据进行占位。之后依次写入每一个属性。例如，以下的数据代表51条需要进行推理的数据。第一行代表所有数据的标签，第二行代表所有数据的第一个属性值，以此类推。

```
1 1 2 1 1 0 1 2 2 1 0 2 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 2 2 0 0 0 0 1 0 0 2 0 2 1 0 2 0 1 1 0 2 1 1 0 2
58 57 50 62 61 60 56 51 54 56 72 48 57 58 63 67 70 63 67 74 63 67 68 60 62 77 66 50 58 65 63 67 63 65 69 73 46 63 55 56 71 50 61 62 52 77 54 64 51 64 50
27 28 35 29 30 30 30 33 39 29 36 30 25 27 28 25 32 23 31 28 25 30 28 29 28 30 30 33 40 30 29 31 34 28 32 29 32 27 42 25 30 32 30 22 27 38 34 32 25 28 35
41 45 13 43 46 48 45 17 13 36 61 14 50 51 51 58 47 44 47 61 50 50 48 45 48 61 44 14 12 55 56 56 56 46 57 63 14 49 14 39 59 12 49 45 39 67 15 45 30 56 16
10 13 3 13 14 18 15 5 4 13 25 3 20 19 15 18 14 13 15 19 19 17 14 15 18 23 14 20 20 18 18 24 24 15 23 18 20 18 20 11 21 20 18 15 14 22 4 15 11 21 6

```

(4) 编译虚拟机并运行

这里分为两种情况：

第一种是使用秘密分享进行推理，那么就编译相应的秘密分享下的虚拟机并运行。我们假设使用的虚拟机是replicated-ring-party.x，运行以下两行代码：

```
make -j 6 replicated-ring-party.x
./Scripts/ring.sh xgboost-inference
```

第二种是使用同态加密进行推理。首先需要保证服务器上已经安装好了微软的seal库，如果没有，则进行安装。

安装命令如下, 或者参照微软的教程https://github.com/microsoft/SEAL
```
git clone https://github.com/microsoft/SEAL.git
cd SEAL
cmake -S . -B build -DSEAL_BUILD_EXAMPLES=ON #下载依赖项，如果报错就重新运行，可能是网络问题
cmake --build build #生成静态库libseal-<version>.a
sudo cmake --install build #将SEAL添加到/usr/local

```



之后运行以下命令进行编译虚拟机

```
make -j 6 tree-inference.x
```

在两个终端下分别运行:

```
./tree-inference.x 0 -pn 10000
```

```
./tree-inference.x 1 -pn 10000
```

#### 更多同态参数调节：

如果需要调节同态加密的参数以及使用的推理时表示小数位数的精度等，可以修改Machines/TreeInferenceServer.h 中的参数，

```
const size_t poly_modulus_degree = 8192; // 多项式的阶数
const uint64_t plain_modulus = 1024; // 明文的模数
const int scale_for_decimal_part = 100; // 用于表示小数的部分，即一个小数a会被表示为 int(a*scale_for_decimal_part)
const int value_max_threhold = 1000; // 当属性值的最大值大于该值时，会进行二维压缩。即一个长度为n的向量被压缩成两个长度根号n的向量
```
